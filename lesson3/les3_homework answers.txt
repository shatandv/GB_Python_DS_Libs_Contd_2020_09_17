1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?
Ответ:
- macro - среднее арифметическое для метрик для каждого класса. (это используется в Scikit-learn)
Здесь абсолютно не важно количество имеющихся экземпляров каждого класса.
(*Что интересно, есть и другой способ подсчитывать macro-F1, хоть он менее рекомендован, чем среднее арифметическое. Это подсчет macro-F1 через macro-recall и macro-precision. Вот интересная статья на эту тему - https://towardsdatascience.com/a-tale-of-two-macro-f1s-8811ddcf8f04).
- weighted - то же, что и macro, но взвешенное по количеству имеющихся экземпляров для каждого класса.
- micro - смотрим на метрики и TP, TN, FP, FN не поклассово, а в общем. То есть количество экземпляров для каждого класса важно при подсчете.
Пример - берем общее число TP, FP, FN вне зависимости от классов. Подсчитываем на их основе micro-precision и micro-recall. Из этих двух метрик можем посчитать micro-F1.


2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?
Ответ:
------